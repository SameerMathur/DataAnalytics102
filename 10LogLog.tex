% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames,x11names}{xcolor}
%
\documentclass[
  letterpaper,
  DIV=11,
  numbers=noendperiod]{scrreport}

\usepackage{amsmath,amssymb}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else  
    % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\setlength{\emergencystretch}{3em} % prevent overfull lines
\setcounter{secnumdepth}{-\maxdimen} % remove section numbering
% Make \paragraph and \subparagraph free-standing
\ifx\paragraph\undefined\else
  \let\oldparagraph\paragraph
  \renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
  \let\oldsubparagraph\subparagraph
  \renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi

\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{241,243,245}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.40,0.45,0.13}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\BuiltInTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\ExtensionTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.28,0.35,0.67}{#1}}
\newcommand{\ImportTok}[1]{\textcolor[rgb]{0.00,0.46,0.62}{#1}}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\NormalTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\RegionMarkerTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.07,0.07,0.07}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}

\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother

\KOMAoption{captions}{tableheading}
\titlehead{
  \begin{center}
    \includegraphics[width=5in]{FINALIZED BOOK COVER.png}
  \end{center}
}
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\AtBeginDocument{%
\ifdefined\contentsname
  \renewcommand*\contentsname{Table of contents}
\else
  \newcommand\contentsname{Table of contents}
\fi
\ifdefined\listfigurename
  \renewcommand*\listfigurename{List of Figures}
\else
  \newcommand\listfigurename{List of Figures}
\fi
\ifdefined\listtablename
  \renewcommand*\listtablename{List of Tables}
\else
  \newcommand\listtablename{List of Tables}
\fi
\ifdefined\figurename
  \renewcommand*\figurename{Figure}
\else
  \newcommand\figurename{Figure}
\fi
\ifdefined\tablename
  \renewcommand*\tablename{Table}
\else
  \newcommand\tablename{Table}
\fi
}
\@ifpackageloaded{float}{}{\usepackage{float}}
\floatstyle{ruled}
\@ifundefined{c@chapter}{\newfloat{codelisting}{h}{lop}}{\newfloat{codelisting}{h}{lop}[chapter]}
\floatname{codelisting}{Listing}
\newcommand*\listoflistings{\listof{codelisting}{List of Listings}}
\makeatother
\makeatletter
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\@ifpackageloaded{subcaption}{}{\usepackage{subcaption}}
\makeatother
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\usepackage{bookmark}

\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same} % disable monospaced font for URLs
\hypersetup{
  colorlinks=true,
  linkcolor={blue},
  filecolor={Maroon},
  citecolor={Blue},
  urlcolor={Blue},
  pdfcreator={LaTeX via pandoc}}

\author{}
\date{}

\begin{document}

\chapter{Log-Log Regression}\label{log-log-regression}

\emph{April 16, 2024}

\section{Overview}\label{overview}

Log-log regression is a statistical technique used to model the
relationship between a dependent variable and one or more independent
variables, where both the dependent and the independent variables
undergo logarithmic transformations. This method is particularly
effective for examining multiplicative relationships and elasticities
between variables that exhibit exponential growth or decline.

\subsection{Purpose}\label{purpose}

\begin{itemize}
\tightlist
\item
  \textbf{Elasticity Analysis:} Log-log regression is commonly employed
  to analyze the elasticity of a variable, which is useful for
  understanding how percentage changes in one variable are associated
  with percentage changes in another.
\item
  \textbf{Scale Invariance:} The logarithmic transformation of both
  dependent and independent variables helps in handling data across
  different scales and makes the model scale-invariant.
\end{itemize}

\section{Business Applications of Log-Log
Regression}\label{business-applications-of-log-log-regression}

\subsection{Marketing}\label{marketing}

The following are some marketing applications of log-log regression:

\textbf{Price Elasticity}: Log-log regression can be used to estimate
the price elasticity of a product's demand. A linear relationship can be
depicted between the \textbf{log of the quantity demanded} and the
\textbf{log of the price} by taking the natural logarithm of both the
dependent and independent variables. The estimated \textbf{price
elasticity of demand} can be used to inform pricing strategies and
maximize revenue for businesses.

\textbf{Advertising Effectiveness:} The effect of advertising on sales
can be estimated using log-log regression. A linear relationship can be
modeled between the \textbf{log of sales} and the \textbf{log of
advertising} expenditure by taking the natural logarithm of both the
dependent and independent variables. The estimated coefficient can be
used to guide advertising expenditure decisions and assist businesses in
optimizing their marketing campaigns.

\textbf{Brand Loyalty:} Log-log regression can be utilized to estimate
the impact of brand loyalty on sales. A linear relationship can be
modeled between the \textbf{log of sales} and the \textbf{log of brand
loyalty} by taking the natural logarithm of both the dependent and
independent variables. The estimated coefficient can be used to
\textbf{inform brand strategy decisions} and assist businesses in
identifying market share expansion opportunities.

\textbf{Market Segmentation Analysis}: Log-log regression can be used to
identify and analyze market segments based on product attributes. A
linear relationship can be modeled between the log of the product
attribute and the log of market share by taking the natural logarithm of
both the dependent and independent variables. Estimates of the resulting
coefficients can be used to determine which product attributes are most
essential to each market segment and to inform decisions regarding
product development. {[}2{]}

\subsection{Finance}\label{finance}

The following are some finance applications of log-log regression:

\textbf{Asset Pricing Models:} Log-log regression can be used to
estimate asset pricing models, such as the capital asset pricing model
(CAPM). By taking the natural logarithm of both the dependent and
independent variables, a linear relationship can be modeled between the
\textbf{log of the expected return} and the \textbf{log of the risk
premium}. The resulting coefficient estimate can be used to inform
investment decisions and help investors evaluate the risk and return of
a portfolio.

\textbf{Risk Management:} Log-log regression can be used to estimate
risk models, such as \textbf{value at risk (VaR)}. By taking the natural
logarithm of both the dependent and independent variables, a linear
relationship can be modeled between the \textbf{log of the portfolio
value} and the \textbf{log of the portfolio risk}. The resulting
coefficient estimate can be used to estimate the level of risk that the
portfolio is exposed to and inform risk management decisions.

\textbf{Option Pricing:} Log-log regression can be used to estimate
option pricing models, such as the Black-Scholes model. By taking the
natural logarithm of both the dependent and independent variables, a
linear relationship can be modeled between the \textbf{log of the stock
price} and the \textbf{log of the option price}. The resulting
coefficient estimate can be used to inform option pricing decisions and
help investors \textbf{evaluate the fair value of an option}.

\textbf{Credit Risk Analysis:} Log-log regression can be used to
estimate credit risk models, such as the \textbf{credit default swap
(CDS) pricing} model. By taking the natural logarithm of both the
dependent and independent variables, a linear relationship can be
modeled between the \textbf{log of the CDS spread} and the \textbf{log
of the credit risk}. The resulting coefficient estimate can be used to
inform credit risk analysis and help investors evaluate the
\textbf{creditworthiness} of a company. {[}3{]}

\subsection{Organizational Behavior}\label{organizational-behavior}

The following are some applications of log-log regression in
Organizational Behavior:

\textbf{Analysis of Employee attrition:}~Log-log regression can be used
to predict employee attrition rates based on a variety of variables,
including compensation, job satisfaction, and work environment. A linear
relationship can be modeled between the log of the employee turnover
rate and the log of the various factors by taking the natural logarithm
of both the dependent and independent variables. Estimates of the
resulting coefficients can be used to identify the most influential
factors influencing employee attrition and inform strategies for
employee retention.

\textbf{Analysis of Employee Performance:}~Log-log regression can be
used to predict employee performance based on a number of variables,
including job training, work experience, and job satisfaction. A linear
relationship can be modeled between the log of employee performance and
the log of the various factors by taking the natural logarithm of both
the dependent and independent variables. The estimated coefficients can
be used to determine the most influential employee performance factors
and to inform training and development strategies.

\textbf{Organizational Culture Analysis:} Analyzing the influence of
organizational culture on employee behavior and attitudes can be
accomplished through the use of log-log regression. By taking the
natural logarithm of both the dependent and independent variables, it is
possible to construct a linear relationship between the log of employee
behavior and attitudes and the log of the different aspects of
organizational culture. The estimated coefficients can be used to
determine the most influential aspects of organizational culture on
employee conduct and attitudes.

\textbf{Leadership Effectiveness Analysis:} Analyzing the influence of
leadership on employee behavior and performance can be accomplished
using log-log regression. A linear relationship can be modeled between
the log of employee behavior and performance and the log of the various
leadership factors by taking the natural logarithm of both the dependent
and independent variables. The estimated coefficients can be used to
identify the most influential leadership factors on employee behavior
and performance, as well as to inform leadership development strategies.
{[}4{]}

\section{Model}\label{model}

\subsection{Model Form}\label{model-form}

The general form of a log-log regression model is represented by the
following equation:

\begin{equation}
\log(Y) = \beta_0 + \beta_1\log(X_1) + \beta_2\log(X_2) + ... + \beta_n\log(X_n) + \epsilon
\end{equation}

where:

\begin{itemize}
\item
  \(Y\) is the dependent variable (after applying the logarithm).
\item
  \(X_1, X_2, ..., X_n\) are the independent variables (after applying
  logarithms to each).
\item
  \(β_0, β_1, ..., β_n\) are the coefficients that the regression model
  aims to estimate.
\item
  \(ε\) is the error term.
\end{itemize}

\subsection{Assumptions}\label{assumptions}

Similar to other regression analyses, log-log regression relies on
several assumptions:

\begin{itemize}
\tightlist
\item
  \textbf{Linearity:} The relationship between the log-transformed
  dependent and independent variables is linear.
\item
  \textbf{Independence:} Observations must be independent of each other.
\item
  \textbf{Homoscedasticity:} The variance of error terms should be
  consistent across different values of independent variables.
\item
  \textbf{Normal Distribution of Errors:} Errors should follow a normal
  distribution for valid hypothesis testing.
\end{itemize}

\subsection{Advantages}\label{advantages}

\begin{itemize}
\tightlist
\item
  \textbf{Interpretability of Elasticities:} The coefficients in a
  log-log model represent the elasticity between variables, providing
  insights into how a percentage change in one variable affects another.
\item
  \textbf{Handling Non-linear Patterns:} By transforming variables
  logarithmically, non-linear relationships can be modeled linearly,
  enhancing the analysis of complex patterns.
\end{itemize}

\subsection{Disadvantages}\label{disadvantages}

\begin{itemize}
\tightlist
\item
  \textbf{Zero Values Problem:} Logarithmic transformation cannot be
  applied directly to zero or negative values, which might require
  additional data adjustments or transformations.
\item
  \textbf{Interpretation Complexity:} Understanding and interpreting
  elasticities might be less straightforward compared to additive
  models, requiring a good grasp of logarithmic relationships. {[}1{]}
\end{itemize}

\section{Estimation}\label{estimation}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  The natural logarithm transformation of both variables can help to
  capture non-linear relationships, stabilize the data variance, and
  clarify the relationship between the variables. The coefficients
  \(β_0\) and \(β_1\) are elasticities that quantify the percentage
  change in the dependent variable for a one percent change in the
  independent variable.
\item
  The \textbf{method of least squares} is used to \textbf{minimize the
  sum of squared residuals} when estimating coefficients. This involves
  determining the values of \(β_0\) and \(β_1\) that minimize the
  difference between the observed and predicted values of the dependent
  variable. {[}5{]}
\end{enumerate}

\section{MODEL 1: Base Model}\label{model-1-base-model}

For reference and a point of comparison, we setup the same base model as
the one used in the previous chapter on Log-Linear Regression.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{data}\NormalTok{(mtcars)}
\FunctionTok{attach}\NormalTok{(mtcars)}
\end{Highlighting}
\end{Shaded}

\subsection{Linear Regression}\label{linear-regression}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(mpg }\SpecialCharTok{\textasciitilde{}}\NormalTok{ wt, }\AttributeTok{data =}\NormalTok{ mtcars)}
\FunctionTok{summary}\NormalTok{(fit)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

Call:
lm(formula = mpg ~ wt, data = mtcars)

Residuals:
    Min      1Q  Median      3Q     Max 
-4.5432 -2.3647 -0.1252  1.4096  6.8727 

Coefficients:
            Estimate Std. Error t value Pr(>|t|)    
(Intercept)  37.2851     1.8776  19.858  < 2e-16 ***
wt           -5.3445     0.5591  -9.559 1.29e-10 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 3.046 on 30 degrees of freedom
Multiple R-squared:  0.7528,    Adjusted R-squared:  0.7446 
F-statistic: 91.38 on 1 and 30 DF,  p-value: 1.294e-10
\end{verbatim}

\section{MODEL 2: Log-Log Model}\label{model-2-log-log-model}

Model 2 adopts a log-log regression approach to explore the relationship
between the weight (\texttt{wt}) of cars and their fuel efficiency
(\texttt{mpg}). In contrast to a simple linear regression model that
predicts \texttt{mpg} directly from \texttt{wt}, this model predicts the
logarithm of \texttt{mpg} from the logarithm of \texttt{wt}. This double
logarithmic transformation is particularly useful for examining how
percentage changes in vehicle weight influence percentage changes in
fuel efficiency, reflecting an elasticity-based relationship between
these variables.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit2 }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(}\FunctionTok{log}\NormalTok{(mpg) }\SpecialCharTok{\textasciitilde{}} \FunctionTok{log}\NormalTok{(wt), }\AttributeTok{data =}\NormalTok{ mtcars)}
\FunctionTok{summary}\NormalTok{(fit2)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

Call:
lm(formula = log(mpg) ~ log(wt), data = mtcars)

Residuals:
     Min       1Q   Median       3Q      Max 
-0.18141 -0.10681 -0.02125  0.08109  0.26930 

Coefficients:
            Estimate Std. Error t value Pr(>|t|)    
(Intercept)  3.90181    0.08790   44.39  < 2e-16 ***
log(wt)     -0.84182    0.07549  -11.15 3.41e-12 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 0.1334 on 30 degrees of freedom
Multiple R-squared:  0.8056,    Adjusted R-squared:  0.7992 
F-statistic: 124.4 on 1 and 30 DF,  p-value: 3.406e-12
\end{verbatim}

\subsection{Model Output and
Interpretation}\label{model-output-and-interpretation}

The results from our log-log regression model are explained below:

\subsubsection{Residuals}\label{residuals}

The residuals, or the \textbf{differences between observed and predicted
values} of \texttt{log(mpg)}, show a \textbf{median close to zero}
(-0.02125), indicating that, on average, the model's predictions closely
match the actual log values. The spread of residuals from the minimum
(-0.18141) to the maximum (0.26930) shows that most predictions fall
within this range, suggesting a reasonable model fit.

\subsubsection{Model Fit}\label{model-fit}

\begin{itemize}
\item
  \textbf{Residual Standard Error (RSE): 0.1334} on 30 degrees of
  freedom indicates the typical deviation of the predicted values from
  the actual values.
\item
  \textbf{Multiple R-squared (0.8056):} About 80.56\% of the variability
  in \texttt{log(mpg)} is explained by the model, indicating a strong
  fit.
\item
  \textbf{Adjusted R-squared (0.7992):} This adjusted statistic accounts
  for the number of predictors and still explains about 79.92\% of the
  variability in \texttt{log(mpg)}, supporting a robust model.
\item
  \textbf{F-statistic (124.4):} This high value and the corresponding
  very low p-value (3.406e-12) affirm the overall significance of the
  model, demonstrating that the model fits the data well and the
  variables are appropriate.
\end{itemize}

\subsubsection{Coefficients}\label{coefficients}

\begin{itemize}
\tightlist
\item
  \textbf{Intercept (3.90181):} This value represents the expected value
  of \texttt{log(mpg)} when \texttt{log(wt)} equals zero. Since
  \texttt{log(wt)} equals zero when \texttt{wt} is 1 (not zero due to
  the nature of logarithmic transformation), this intercept can be
  interpreted as the expected log of mpg for a car with a weight of 1
  unit.
\end{itemize}

To find the fuel efficiency (mpg) of a car with a weight of 1 unit, we
can use the intercept value from the log-log regression model. The
calculation involves converting \texttt{log(mpg)} back to \texttt{mpg}
using the exponential function:

\[
\text{mpg} = e^{\text{intercept}} = e^{3.90181}
\]

Evaluating this expression yields:

\[
\text{mpg} = 49.49
\]

This result indicates that the \textbf{mpg for a car weighing 1 unit is
approximately 49.49 miles per gallon}.

\begin{itemize}
\tightlist
\item
  \textbf{log(wt) Coefficient (-0.84182):} This coefficient indicates
  the expected change in \texttt{log(mpg)} for each one-unit increase in
  \texttt{log(wt)}. Specifically, \textbf{a one-unit increase in
  \texttt{log(wt)} is associated with a decrease of 0.84182 in}
  \textbf{\texttt{log(mpg)}}. This negative coefficient reflects a
  strong inverse relationship, suggesting that as car weight increases
  on a logarithmic scale, fuel efficiency decreases.
\end{itemize}

In practical terms, a \textbf{1\% increase in a car's weight leads to an
approximate 0.84182\% decrease in its fuel efficiency}.

This is interpreted as the \textbf{elasticity of mpg with respect to
weight}, indicating a highly elastic relationship where small percentage
changes in weight lead to substantial percentage changes in mpg.

Therefore, the beta coefficient of -0.84182 indicates a strong negative
elasticity, signifying that increases in car weight have a substantial
negative impact on fuel efficiency, all else being constant.

In contrast, \textbf{in the linear-linear model, the relationship was
additive rather than multiplicative}, with each unit increase in weight
reducing the mpg linearly by 0.27178 units.

\subsubsection{Statistical Significance}\label{statistical-significance}

In the log-log regression model, we conduct hypothesis testing for each
coefficient separately to assess their statistical significance in
predicting the dependent variable, \texttt{log(mpg)}. Here's how we
define and interpret the tests for the intercept and \texttt{log(wt)}:

\begin{itemize}
\tightlist
\item
  \textbf{For the Intercept:}

  \begin{itemize}
  \tightlist
  \item
    \textbf{Null Hypothesis (H0):} The intercept is zero, suggesting it
    has no effect on \texttt{log(mpg)} when all independent variables
    are zero (logarithmically speaking).
  \item
    \textbf{Alternative Hypothesis (H1):} The intercept is not zero,
    indicating it does affect \texttt{log(mpg)} and provides a baseline
    level of mpg when \texttt{wt} equals 1 unit (since
    \texttt{log(1)\ =\ 0}).
  \item
    \textbf{Result:} Given that the p-value for the intercept is
    significantly below 0.05, we reject the null hypothesis. This means
    there is strong statistical evidence that the intercept is a
    significant contributor to the model, affecting the baseline mpg
    calculation.
  \end{itemize}
\item
  \textbf{For \texttt{log(wt)}:}

  \begin{itemize}
  \tightlist
  \item
    \textbf{Null Hypothesis (H0):} The coefficient for \texttt{log(wt)}
    is zero, implying no relationship between weight and mpg on a
    logarithmic scale.
  \item
    \textbf{Alternative Hypothesis (H1):} The coefficient for
    \texttt{log(wt)} is not zero, suggesting that changes in weight have
    a significant effect on mpg.
  \item
    \textbf{Result:} The very low p-value associated with the
    \texttt{log(wt)} coefficient leads us to reject the null hypothesis.
    This rejection provides substantial evidence that an increase in
    weight significantly decreases mpg, affirming the predictive power
    of \texttt{log(wt)} in the model.
  \end{itemize}
\end{itemize}

The statistical tests confirm that both the baseline level of mpg and
the effect of weight changes are significant factors in the model.

\section{Another Log-Log Model}\label{another-log-log-model}

We present two regression models, Model 3a (Linear-Linear Model) and
Model 3b (Log-Log Model), using the \texttt{mtcars} dataset. Both models
aim to predict the miles per gallon (\texttt{mpg}) of cars based on
their weight (\texttt{wt}) and transmission type (\texttt{am}, with
levels ``Automatic'' and ``Manual'').

\subsection{MODEL 3a - Linear-Linear
Model}\label{model-3a---linear-linear-model}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Convert am to a factor variable}
\NormalTok{mtcars}\SpecialCharTok{$}\NormalTok{am }\OtherTok{\textless{}{-}} \FunctionTok{factor}\NormalTok{(mtcars}\SpecialCharTok{$}\NormalTok{am, }\AttributeTok{labels =} \FunctionTok{c}\NormalTok{(}\StringTok{"Automatic"}\NormalTok{, }\StringTok{"Manual"}\NormalTok{))}

\NormalTok{fit3a }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{((mpg) }\SpecialCharTok{\textasciitilde{}}\NormalTok{ wt }\SpecialCharTok{+}\NormalTok{ am, }\AttributeTok{data =}\NormalTok{ mtcars)}
\FunctionTok{summary}\NormalTok{(fit3a)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

Call:
lm(formula = (mpg) ~ wt + am, data = mtcars)

Residuals:
    Min      1Q  Median      3Q     Max 
-4.5295 -2.3619 -0.1317  1.4025  6.8782 

Coefficients:
            Estimate Std. Error t value Pr(>|t|)    
(Intercept) 37.32155    3.05464  12.218 5.84e-13 ***
wt          -5.35281    0.78824  -6.791 1.87e-07 ***
amManual    -0.02362    1.54565  -0.015    0.988    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 3.098 on 29 degrees of freedom
Multiple R-squared:  0.7528,    Adjusted R-squared:  0.7358 
F-statistic: 44.17 on 2 and 29 DF,  p-value: 1.579e-09
\end{verbatim}

\section{MODEL 3b: Another Log-Log
Model}\label{model-3b-another-log-log-model}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit3b }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(}\FunctionTok{log}\NormalTok{(mpg) }\SpecialCharTok{\textasciitilde{}} \FunctionTok{log}\NormalTok{(wt) }\SpecialCharTok{+}\NormalTok{ am, }\AttributeTok{data =}\NormalTok{ mtcars)}
\FunctionTok{summary}\NormalTok{(fit3b)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

Call:
lm(formula = log(mpg) ~ log(wt) + am, data = mtcars)

Residuals:
      Min        1Q    Median        3Q       Max 
-0.194110 -0.117056 -0.008833  0.071274  0.258052 

Coefficients:
            Estimate Std. Error t value Pr(>|t|)    
(Intercept)  4.04162    0.14480  27.911  < 2e-16 ***
log(wt)     -0.93629    0.10822  -8.652 1.58e-09 ***
amManual    -0.08329    0.06886  -1.210    0.236    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 0.1324 on 29 degrees of freedom
Multiple R-squared:  0.815, Adjusted R-squared:  0.8022 
F-statistic: 63.87 on 2 and 29 DF,  p-value: 2.369e-11
\end{verbatim}

\subsection{Model Output and
Interpretation}\label{model-output-and-interpretation-1}

The output from Model 3b highlights the relationship between the
logarithm of miles per gallon (\texttt{mpg}) and factors including the
logarithm of car weight (\texttt{wt}) and transmission type
(\texttt{am}). Below, we detail the interpretation of the model's
results:

\subsubsection{Residuals}\label{residuals-1}

\begin{itemize}
\tightlist
\item
  The residuals of the model show a median very close to zero
  (-0.008833) and are relatively tightly distributed, ranging from
  -0.194110 to 0.258052. This tight clustering indicates that the model
  predictions are generally close to the observed data, demonstrating a
  good fit.
\end{itemize}

\subsubsection{Coefficients}\label{coefficients-1}

\begin{itemize}
\item
  \textbf{Intercept (4.04162):} The intercept, statistically highly
  significant with a p-value much less than 0.05, represents the
  expected value of \texttt{log(mpg)} when \texttt{log(wt)} equals zero
  and when the car has an automatic transmission. The high t-value
  (27.911) underlines its statistical reliability. For practical
  purposes, this value can be interpreted as the expected log of mpg for
  a hypothetically light car with a weight of 1 unit (since
  \texttt{log(1)\ =\ 0}) and an automatic transmission.
\item
  \textbf{log(wt) Coefficient (-0.93629):} The coefficient for
  \texttt{log(wt)} is negative, indicating that as the weight of a car
  increases, its fuel efficiency decreases. The elasticity of mpg with
  respect to weight is about -0.936, meaning that a 1\% increase in
  weight leads to roughly a 0.936\% decrease in mpg. This relationship
  is statistically significant, with a very low p-value (1.58e-09) and a
  strong t-value (-8.652), suggesting a strong and reliable negative
  impact of weight on fuel efficiency.
\item
  \textbf{amManual (-0.08329):} This coefficient is associated with cars
  having manual transmissions compared to the baseline of automatic
  transmissions. The negative sign suggests a decrease in fuel
  efficiency for manual compared to automatic, but this result is not
  statistically significant (p-value = 0.236), indicated by a t-value of
  -1.210. It implies that, after controlling for weight, the type of
  transmission (manual vs.~automatic) does not have a significant effect
  on the mpg in this dataset.
\end{itemize}

\subsubsection{Model Fit and Statistics}\label{model-fit-and-statistics}

\begin{itemize}
\tightlist
\item
  \textbf{Residual Standard Error (0.1324):} The RSE is quite low, which
  reflects the small average distance of the data points from the fitted
  line, indicating a good fit.
\item
  \textbf{Multiple R-squared (0.815):} Approximately 81.5\% of the
  variation in \texttt{log(mpg)} is explained by the combined effects of
  \texttt{log(wt)} and transmission type. This high R-squared value
  shows that the model does a good job of capturing the relationship
  between these variables.
\item
  \textbf{Adjusted R-squared (0.8022):} Adjusted for the number of
  predictors, it confirms that the model explains a significant amount
  of the variability in \texttt{log(mpg)}.
\item
  \textbf{F-statistic (63.87):} This value tests the overall
  significance of the regression model, and the associated p-value
  (2.369e-11) indicates the model is statistically significant.
\end{itemize}

This analysis reveals that weight is a critical factor in predicting the
fuel efficiency of cars, with significant impacts demonstrated through
the log-log regression model. However, the transmission type does not
show a statistically significant influence on mpg when considering this
dataset.

\subsubsection{Model Prediction}\label{model-prediction}

To illustrate the prediction of fuel efficiency using Model 3b for a car
with a weight of 2 units, we'll calculate the predicted \texttt{mpg} for
both automatic and manual transmission types using the regression
coefficients obtained from the log-log model. Below are the steps
involved:

\subsection{Model Equations and
Coefficients}\label{model-equations-and-coefficients}

The model formula based on the regression output is expressed as:

\[
\log(\text{mpg}) = \beta_0 + \beta_1\log(\text{wt}) + \beta_2\text{amManual}
\]

where: \[
\beta_0 \text{ (Intercept)} = 4.04162,
\] \[
\beta_1 \text{ (Coefficient for } \log(\text{wt})) = -0.93629,
\] \[
\beta_2 \text{ (Coefficient for } \text{amManual}) = -0.08329
\]

\subsection{Calculation for an Automatic Transmission Car (wt = 2 units,
am =
0)}\label{calculation-for-an-automatic-transmission-car-wt-2-units-am-0}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{Log of Weight}: Since ( \text{wt} = 2 ), we calculate (
  \log(2) \approx 0.693 ).
\item
  \textbf{Substitute into Model}: \[
  \log(\text{mpg}) = 4.04162 + (-0.93629 \times 0.693) + (-0.08329 \times 0)
  \] \[
  \log(\text{mpg}) = 4.04162 - 0.64874
  \] \[
  \log(\text{mpg}) = 3.39288
  \]
\item
  \textbf{Exponentiate to find MPG}: \[
  \text{mpg} = e^{3.39288} \approx 29.76
  \]
\end{enumerate}

\subsection{Calculation for a Manual Transmission Car (wt = 2 units, am
= 1)}\label{calculation-for-a-manual-transmission-car-wt-2-units-am-1}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{Log of Weight}: ( \log(2) \approx 0.693 ) (same as before).
\item
  \textbf{Substitute into Model}: \[
  \log(\text{mpg}) = 4.04162 + (-0.93629 \times 0.693) + (-0.08329 \times 1)
  \] \[
  \log(\text{mpg}) = 4.04162 - 0.64874 - 0.08329
  \] \[
  \log(\text{mpg}) = 3.30959
  \]
\item
  \textbf{Exponentiate to find MPG}: \[
  \text{mpg} = e^{3.30959} \approx 27.36
  \]
\end{enumerate}

\subsection{Interpretation}\label{interpretation}

\begin{itemize}
\tightlist
\item
  \textbf{Automatic Transmission Car}: A car with an automatic
  transmission and a weight of 2 units is predicted to have an
  \texttt{mpg} of approximately 29.76. This demonstrates that, even with
  an increase in weight, the car maintains relatively high fuel
  efficiency.
\item
  \textbf{Manual Transmission Car}: A car with a manual transmission and
  the same weight has a slightly lower predicted \texttt{mpg} of about
  27.36. The negative coefficient for manual transmission, though not
  statistically significant, suggests a minor reduction in fuel
  efficiency compared to an automatic transmission model.
\end{itemize}

These calculations clearly show how the log-log model can be applied to
predict the impact of weight and transmission type on the fuel
efficiency of cars. The significant negative impact of weight, as shown
by the elasticity coefficient, highlights the strong influence of weight
increase on reducing fuel efficiency, which is consistent with general
automotive principles.

\section{References}\label{references}

{[}1{]} Stock, J. H., \& Watson, M. W. (2002). Introduction to
econometrics. New York: Addison Wesley.

Jaccard, J., \& Turrisi, R. (2003). Interaction effects in multiple
regression. Sage Publications.

Long, J. S. (1997). Regression models for categorical and limited
dependent variables. Sage Publications.

Greene, W. H. (2012). Econometric analysis. Pearson Education.

Hill, R. C., Griffiths, W. E., \& Lim, G. C. (2018). Principles of
econometrics. John Wiley \& Sons.

{[}2{]} Anderson, E. T., \& Simester, D. I. (2011). Price elasticity of
demand in online retail markets. Journal of Marketing Research, 48(2),
316-327.

Tellis, G. J. (2004). Effective advertising: Understanding when, how,
and why advertising works. Sage Publications.

Rust, R. T., Zeithaml, V. A., \& Lemon, K. N. (2004). Customer-centered
brand management. Harvard Business Review, 82(9), 110-118.

Wedel, M., \& Kamakura, W. A. (2001). Market segmentation: Conceptual
and methodological foundations. Kluwer Academic Publishers.

Kim, K. H., \& Kumar, V. (2014). An empirical examination of the
determinants of retail prices and promotional markdowns using
store-level data. Journal of Retailing, 90(1), 43-55.

{[}3{]} Fama, E. F., \& French, K. R. (1992). The cross-section of
expected stock returns. The Journal of Finance, 47(2), 427-465.

Alexander, C. (2008). Market risk analysis, value at risk models. Wiley
Finance.

Black, F., \& Scholes, M. (1973). The pricing of options and corporate
liabilities. Journal of Political Economy, 81(3), 637-654.

Duffie, D., \& Singleton, K. (1999). Modeling term structures of
defaultable bonds. Review of Financial Studies, 12(4), 687-720.

Hull, J. (2018). Options, futures, and other derivatives. Pearson
Education.

{[}4{]} Hom, P. W., Caranikas-Walker, F., Prussia, G. E., \& Griffeth,
R. W. (1992). A meta-analytical structural equations analysis of a model
of employee turnover. Journal of Applied Psychology, 77(6), 890-909.

Griffin, M. A., \& Neal, A. (2000). Perceptions of safety at work: A
framework for linking safety climate to safety performance, knowledge,
and motivation. Journal of Occupational Health Psychology, 5(3),
347-358.

Schein, E. H. (2010). Organizational culture and leadership (4th ed.).
John Wiley \& Sons.

Avolio, B. J., \& Bass, B. M. (1991). The full range leadership
development program: Manual for the multifactor leadership
questionnaire. Mind Garden.

Cascio, W. F. (1991). Costing human resources: The financial impact of
behavior in organizations (3rd ed.). PWS-Kent Publishing Company.

{[}5{]} Wooldridge, J. M. (2015). Introductory econometrics: A modern
approach. Nelson Education.

Gujarati, D. N. (2003). Basic econometrics (4th ed.). McGraw-Hill.

Stock, J. H., \& Watson, M. W. (2002). Introduction to econometrics.
Addison Wesley.

Hill, R. C., Griffiths, W. E., \& Lim, G. C. (2018). Principles of
econometrics (5th ed.). John Wiley \& Sons.

Long, J. S. (1997). Regression models for categorical and limited
dependent variables. Sage Publications.

{[}6{]}



\end{document}
